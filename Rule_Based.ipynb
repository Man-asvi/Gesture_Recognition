{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def classify_gesture(landmarks):\n",
    "    finger_tips = [8, 12, 16, 20]   # Index to Pinky\n",
    "    finger_pips = [6, 10, 14, 18]   # PIP joints\n",
    "    finger_states = [landmarks[tip].y < landmarks[pip].y for tip, pip in zip(finger_tips, finger_pips)]\n",
    "\n",
    "    thumb_extended = landmarks[4].x < landmarks[3].x\n",
    "    index_extended = finger_states[0]\n",
    "    middle_extended = finger_states[1]\n",
    "    ring_extended = finger_states[2]\n",
    "    pinky_extended = finger_states[3]\n",
    "\n",
    "    if not any(finger_states) and not thumb_extended:\n",
    "        return \"Fist\"\n",
    "    elif index_extended and middle_extended and not ring_extended and not pinky_extended and not thumb_extended:\n",
    "        return \"Peace\"\n",
    "    elif all(finger_states):\n",
    "        return \"Hi\"\n",
    "    elif thumb_extended and pinky_extended and not any([index_extended, middle_extended, ring_extended]):\n",
    "        return \"YOLO\"\n",
    "    elif thumb_extended and index_extended and pinky_extended and not middle_extended and not ring_extended:\n",
    "        return \"Rockstar\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.7) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb)\n",
    "        frame = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                gesture = classify_gesture(hand_landmarks.landmark)\n",
    "                text_size = cv2.getTextSize(gesture, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 3)[0]\n",
    "                text_x = frame.shape[1] - text_size[0] - 10  # 10 pixels from right\n",
    "                text_y = 40\n",
    "                cv2.rectangle(frame,\n",
    "                            (text_x - 5, text_y - text_size[1] - 5),\n",
    "                            (text_x + text_size[0] + 5, text_y + 5),\n",
    "                            (0, 0, 0), -1)\n",
    "                cv2.putText(frame, gesture, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)\n",
    "                cv2.imshow(\"Gesture Recognition\", frame)\n",
    "                if cv2.waitKey(5) & 0xFF == 27:  \n",
    "                    break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
